{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "eCorp-code.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOCy3wZ5vWQa5JRMAvpJcfr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abhymanyu/SalaryPredictionPortfolio/blob/main/eCorp_code.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RIixXdXGcBJF"
      },
      "source": [
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "#!pip install tqdm\r\n",
        "from tqdm import tqdm\r\n",
        "\r\n",
        "__author__ = 'DSDJ Team'\r\n",
        "__email__ = 'info@datasciencedreamjob.com'\r\n",
        "__website__ = 'www.datasciencedreamjob.com'\r\n",
        "\r\n",
        "__copyright__ = 'Copyright 2018, Data Science Dream Job LLC'"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hk8YwtQkpnte",
        "outputId": "6ddec71d-a76b-4c32-a6e9-b2e89d4cc051"
      },
      "source": [
        "!pip install PyDrive\r\n",
        "from pydrive.auth import GoogleAuth\r\n",
        "from pydrive.drive import GoogleDrive\r\n",
        "from google.colab import auth\r\n",
        "from oauth2client.client import GoogleCredentials\r\n",
        "\r\n",
        "auth.authenticate_user()\r\n",
        "gauth = GoogleAuth()\r\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\r\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: PyDrive in /usr/local/lib/python3.6/dist-packages (1.3.1)\n",
            "Requirement already satisfied: google-api-python-client>=1.2 in /usr/local/lib/python3.6/dist-packages (from PyDrive) (1.7.12)\n",
            "Requirement already satisfied: oauth2client>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from PyDrive) (4.1.3)\n",
            "Requirement already satisfied: PyYAML>=3.0 in /usr/local/lib/python3.6/dist-packages (from PyDrive) (3.13)\n",
            "Requirement already satisfied: google-auth>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->PyDrive) (1.17.2)\n",
            "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->PyDrive) (3.0.1)\n",
            "Requirement already satisfied: httplib2<1dev,>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->PyDrive) (0.17.4)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->PyDrive) (0.0.4)\n",
            "Requirement already satisfied: six<2dev,>=1.6.1 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->PyDrive) (1.15.0)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->PyDrive) (4.6)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->PyDrive) (0.2.8)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->PyDrive) (0.4.8)\n",
            "Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.4.1->google-api-python-client>=1.2->PyDrive) (51.1.1)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.4.1->google-api-python-client>=1.2->PyDrive) (4.2.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sO8xDsqbqQWL"
      },
      "source": [
        "### Define Recommender Class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "izhoBAWrp8SV"
      },
      "source": [
        "class Recommender:\r\n",
        "    def __init__(self, data, user_col, item_cols, cf_method='item', similarity='pearson'):\r\n",
        "        '''init Recommender class'''\r\n",
        "        self.data = data\r\n",
        "        self.user_col = user_col\r\n",
        "        self.item_cols = item_cols\r\n",
        "        self.cf_method = cf_method\r\n",
        "        self.similarity = similarity\r\n",
        "        self.similarity_matrix = []\r\n",
        "        self.user_scores = []\r\n",
        "        self.recs = []\r\n",
        "\r\n",
        "    def create_similarity_matrix(self):\r\n",
        "        '''creates correlation/similarity matrix for all items and stores result and self.similarity_matrix'''\r\n",
        "        self.similarity_matrix = self._create_empty_df(self.cf_method)\r\n",
        "        self._fill_similarity_matrix(self.similarity_matrix, self.similarity)\r\n",
        "\r\n",
        "    def score_users(self, users=None):\r\n",
        "        '''generates item ratings for each item for each user and stores result as self.user_scores'''\r\n",
        "        if not users:\r\n",
        "            # grab all users in data by default\r\n",
        "            users = self.data.loc[:,self.user_col]\r\n",
        "        cols = [self.user_col] + list(self.item_cols)\r\n",
        "        user_data = self.data.loc[:,cols].set_index(self.user_col)\r\n",
        "        self.user_scores = pd.DataFrame(index=users, columns=self.item_cols)\r\n",
        "        self.user_scores = self.data[self.item_cols].dot(self.similarity_matrix)\r\n",
        "                \r\n",
        "    def score_new_users(self, users, user_data):\r\n",
        "        '''generates item ratings for users passed in from external data set and stores result as self.user_scores'''\r\n",
        "        cols = [self.user_col] + list(self.item_cols)\r\n",
        "        self.user_scores = pd.DataFrame(index=user_data.index, columns=self.item_cols)\r\n",
        "        self.user_scores = user_data.loc[self.item_cols].dot(self.similarity_matrix)        \r\n",
        "                \r\n",
        "    def generate_recs(self, users=None, num_recs=5):\r\n",
        "        '''generates top num_rec recommendations for users and stores result as self.recs'''\r\n",
        "        if not users:\r\n",
        "            # grab all users in data by default\r\n",
        "            users = self.data.loc[:,self.user_col]\r\n",
        "        cols = ['Rec ' + str(x) for x in range(1,num_recs+1)] + ['Score ' + str(x) for x in range(1,num_recs+1)]\r\n",
        "        self.recs = pd.DataFrame(index=users, columns=cols)\r\n",
        "        progress_bar = tqdm(total = len(users), mininterval=5)\r\n",
        "        for user in users:\r\n",
        "            progress_bar.update()\r\n",
        "            sorted_items = self.user_scores.sort_values(by=user, ascending=False, axis=1).loc[user,:].index\r\n",
        "            for i in range(num_recs):\r\n",
        "                item = sorted_items[i]\r\n",
        "                item_col = cols[i]\r\n",
        "                score_col = cols[i+num_recs]\r\n",
        "                self.recs.loc[user, item_col] = item\r\n",
        "                self.recs.loc[user, score_col] = self.user_scores.loc[user, item]\r\n",
        "        self.recs.reset_index(inplace=True, drop=False)\r\n",
        "\r\n",
        "    def print_recs(self):\r\n",
        "        '''prints self.recs to stdout'''\r\n",
        "        print(self.recs)\r\n",
        "        \r\n",
        "    def save_recs(self, filename='recommendations', format='excel'):\r\n",
        "        '''saves self.recs to filename in specified format'''\r\n",
        "        drive.mount('/gdrive'\r\n",
        "        if format == 'excel':\r\n",
        "            extension ='.xlsx'\r\n",
        "            #self.recs.to_excel(filename + extension, index=False)\r\n",
        "            self.recs.to_excel('/gdrive/My Drive/DataScienceDreamJob-e-corp-data/' + filename + extension, index=False)\r\n",
        "        elif format == 'csv':\r\n",
        "            extension += '.csv'\r\n",
        "            #self.recs.to_csv(filename + extension, index=False)\r\n",
        "            self.recs.to_csv('/gdrive/My Drive/DataScienceDreamJob-e-corp-data/' + filename + extension, index=False)\r\n",
        "        else:\r\n",
        "            raise ValueError('Invalid file format.  Please specify \"excel\" or \"csv\".')\r\n",
        "  \r\n",
        "    def _create_empty_df(self, cf_type):\r\n",
        "        '''creates and returns empty df with users or items as rows and columns'''\r\n",
        "        if cf_type == 'item':\r\n",
        "            labels = self.item_cols\r\n",
        "        elif cf_type == 'user':\r\n",
        "            labels = self.data[user_col]\r\n",
        "        else:\r\n",
        "            raise ValueError('Invalid collaborative filtering technique.  Please specify \"item\" or \"user\".')\r\n",
        "        return pd.DataFrame(index=labels, columns=labels)\r\n",
        "\r\n",
        "    def _fill_similarity_matrix(self, similarity_matrix, similarity):\r\n",
        "        '''calculates correlation between items using specified similarity and saves results in similarity_matrix\r\n",
        "           valid similarity types: jaccard, pearson, cosine'''\r\n",
        "        k=0\r\n",
        "        item_df = self.data[self.item_cols] \r\n",
        "        #print(item_df)\r\n",
        "        progress_bar = tqdm(total = similarity_matrix.shape[0], mininterval=5)\r\n",
        "        for i in range(similarity_matrix.shape[0]):\r\n",
        "            progress_bar.update()\r\n",
        "            similarity_matrix.ix[i,i] = 1.0\r\n",
        "            x = item_df.ix[:,i]\r\n",
        "            for j in range(i,similarity_matrix.shape[1]):\r\n",
        "                y = item_df.ix[:,j]\r\n",
        "                similarity_matrix.ix[i,j] = self._get_similarity(x, y, similarity)\r\n",
        "                similarity_matrix.ix[j,i] = similarity_matrix.ix[i, j]\r\n",
        "                \r\n",
        "    def _get_similarity(self, x, y, similarity):\r\n",
        "        '''calculated specified correlation between two vectors and returns result'''\r\n",
        "        if similarity == 'pearson':\r\n",
        "            return self._pearson_similarity(x, y)\r\n",
        "        elif similarity == 'jaccard':\r\n",
        "            return self._jaccard_similarity(x, y)\r\n",
        "        elif similarity == 'cosine':\r\n",
        "            return self._cosine_similarity(x, y)\r\n",
        "        else:\r\n",
        "            raise ValueError('Invalid similarity type.  Please specify \"cosine\", \"pearson\", or \"jaccard\".')\r\n",
        "        \r\n",
        "    def _pearson_similarity(self, x, y):\r\n",
        "        '''returns pearson correlation between x and y: covariance(x,y)/(std_dev(x)*std_dev(y))'''\r\n",
        "        #effective if data can be transformed to normal distribution \r\n",
        "        pass\r\n",
        "\r\n",
        "    def _jaccard_similarity(self, x, y):\r\n",
        "        '''returns jaccard correlation between x and y: |intsection(x,y)|/|union(x,y)|'''\r\n",
        "        #ideal for binary data, e.g. buy vs non-buy\r\n",
        "        nonzero_x = set(np.nonzero(x)[0])\r\n",
        "        nonzero_y = set(np.nonzero(y)[0])\r\n",
        "        intersection_size = len(nonzero_x.intersection(nonzero_y))\r\n",
        "        union_size = len(nonzero_x.union(nonzero_y))\r\n",
        "        if union_size == 0:\r\n",
        "            return 0\r\n",
        "        else:\r\n",
        "            return intersection_size/union_size\r\n",
        "\r\n",
        "    def _cosine_similarity(self, x, y):\r\n",
        "        '''returns cosine of angles between x and y'''\r\n",
        "        pass\r\n",
        "    "
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lX5ZTG23qWjz"
      },
      "source": [
        "Define Data Class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6SKctK57qBV8"
      },
      "source": [
        "class Data:\r\n",
        "    def __init__(self):\r\n",
        "        '''init Data class'''\r\n",
        "        self.data = None\r\n",
        "        \r\n",
        "    def load_data(self, filename, format='txt'):\r\n",
        "        '''loads data from excel, csv, tsv, or txt file'''\r\n",
        "        if format == 'excel':\r\n",
        "            self.data = pd.read_excel(filename)\r\n",
        "        elif format == 'csv':\r\n",
        "            self.data = pd.read_csv(filename)\r\n",
        "        elif format == 'tsv':\r\n",
        "            self.data = pd.read_csv(filename, sep='\\t')\r\n",
        "        elif format == 'txt':\r\n",
        "            self.data = pd.read_table(filename)\r\n",
        "        else:\r\n",
        "            raise ValueError('Invalid file format.  Please specify \"excel\", \"csv\", \"tsv\", or \"txt\".')\r\n",
        "    \r\n",
        "    def drop_small_orders(self, order_col='order_number', min_order_size=2):\r\n",
        "        '''drop orders from self.data that have min_order_size or less unique items in basket'''\r\n",
        "        self.data = self.data[self.data.groupby('order_number').order_number.transform(len) >= min_order_size]\r\n",
        "    \r\n",
        "    def expand_columns(self, columns=[]):\r\n",
        "        '''performs one-hot encoding on specified columns and appends them to self.data'''\r\n",
        "        dfs = []\r\n",
        "        dfs.append(data.data)\r\n",
        "        for col in columns:\r\n",
        "            dfs.append(pd.get_dummies(self.data[col], prefix=None, sparse=False))\r\n",
        "        data.data = pd.concat(dfs, axis=1)\r\n",
        "          \r\n",
        "    def drop_columns(self, columns=[]):\r\n",
        "        '''drops columns from self.data'''\r\n",
        "        self.data.drop(columns, axis=1, inplace=True)\r\n",
        "        \r\n",
        "    def consolidate_orders(self, order_col='order_number'):\r\n",
        "        '''consolidates each order in self.data into single record.  order number is maintained and all other columns summed.'''\r\n",
        "        data_cols = list(data.data.columns)\r\n",
        "        data_cols.remove(order_col)\r\n",
        "        self.data = self.data.groupby(order_col).sum()[data_cols].reset_index()"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A6lAXbW1qNQd"
      },
      "source": [
        "### *Set Data Flow*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IYUO2yuwqF9K"
      },
      "source": [
        "load_and_process_data = True\r\n",
        "get_columns = True\r\n",
        "run_rec_engine = True"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1gXveCHoupBm"
      },
      "source": [
        "Load text file into DataFrame and process data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V0OYb76pus10"
      },
      "source": [
        "if load_and_process_data:\r\n",
        "    # drop orders with few items, one-hot encode l3 category information, drop unnecessary columns, \r\n",
        "    # and consolidate unique orders into single records\r\n",
        "    \r\n",
        "    #Connect to Google drive with a Pydrive wrapper\r\n",
        "    #https://drive.google.com/file/d/15eUAlV-AJi28U74hgsvTWOY4N0fWGTq-/view?usp=sharing\r\n",
        "    downloaded = drive.CreateFile({'id':\"15eUAlV-AJi28U74hgsvTWOY4N0fWGTq-\"})  \r\n",
        "    downloaded.GetContentFile('All Transations - 2 Weeks.txt')  \r\n",
        "    \r\n",
        "    data = Data()\r\n",
        "    data.load_data('All Transations - 2 Weeks.txt', format='tsv')\r\n",
        "    data.drop_small_orders(order_col='order_number', min_order_size=20)\r\n",
        "    data.expand_columns(['l3'])  \r\n",
        "    data.drop_columns(['l1', 'l2', 'l3', 'sku', 'brand'])\r\n",
        "    data.consolidate_orders(order_col='order_number')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hB_PvvdhuuJd"
      },
      "source": [
        "Grab column names"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ejLJ0L5VuuY6"
      },
      "source": [
        "if get_columns:\r\n",
        "    user_col = 'order_number'\r\n",
        "    item_cols = list(data.data.columns)\r\n",
        "    item_cols.remove(user_col)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JkOySddKrWp3"
      },
      "source": [
        "### Run rec engine and generate results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oXkwAfT-rV9M"
      },
      "source": [
        "from google.colab import drive\r\n",
        "\r\n",
        "if run_rec_engine:\r\n",
        "    rec_engine = Recommender(data.data, user_col=user_col, item_cols=item_cols, cf_method='item', similarity='jaccard')\r\n",
        "    rec_engine.create_similarity_matrix()\r\n",
        "    rec_engine.score_users()\r\n",
        "    rec_engine.generate_recs()\r\n",
        "    rec_engine.save_recs()\r\n",
        "    rec_engine.print_recs()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}